{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains scripts for CountMinSketch implementation testing\n",
    "\n",
    "It uses prefix of a preprocessed wiki corpus (title_tokens) as a source, processing at most fixed amount of text. It counts the frequency of words using the python Counter (dictionary) for exact counts and then repeats the counting using Count-min sketch implementation.\n",
    "Basic statistics such as standard deviation are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bounter\n",
    "import math\n",
    "import smart_open\n",
    "import numpy \n",
    "\n",
    "# some basic declarations about input\n",
    "\n",
    "# process at most this number of articles \n",
    "max_articles = 100 \n",
    "# process at most this number of total words\n",
    "max_words = 150000000\n",
    "#absolute path to corpus\n",
    "wiki_file = 'C:/rare/corpus/wiki/title_tokens.txt.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048576 4\n16\n"
     ]
    }
   ],
   "source": [
    "from bounter import CountMinSketch as CMS\n",
    "cms = CMS(16, algorithm=\"basic\")\n",
    "print(cms.width, cms.depth)\n",
    "print(cms.size() // (1024*1024))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads the counter from wiki file\n",
    "# cnt (python counter) or cms (count-min sketch) can be None, it only loads into a non-empty counter\n",
    "# returns total number of loaded words\n",
    "def load(cnt, cms):\n",
    "    wiki_input = smart_open.smart_open(wiki_file)\n",
    "    wiki_input.seek(0)\n",
    "\n",
    "    length = 0\n",
    "    words = 0\n",
    "    for lineno, line in enumerate(wiki_input):            \n",
    "        length += 1                \n",
    "        for word in line.decode().split('\\t')[1].split():\n",
    "            if cnt is not None:\n",
    "                cnt[word] += 1\n",
    "            if cms is not None:\n",
    "                cms.increment(word)\n",
    "            words += 1\n",
    "        if (length >= max_articles or words >= max_words):\n",
    "            break\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using cnt as counter with exact frequencies and cms as count-min sketch estimations,\n",
    "# provides basic statistics about the accuracy of the estimations\n",
    "# deviation: standard deviation of the estimations\n",
    "# log_deviation: standard deviation using the logcounter value instead of the derived value\n",
    "\n",
    "mks1024 = bounter.CountMinSketch(width=1, depth=1, algorithm='logcounter1024')\n",
    "\n",
    "def stats(cnt, cms):\n",
    "    variance = 0\n",
    "    logvariance = 0\n",
    "    total_estimated_freq = 0\n",
    "    total_real_freq = 0\n",
    "    total_keys = 0\n",
    "    mds = 0\n",
    "    md = 0\n",
    "    mdw = ''\n",
    "    mdc = 0\n",
    "    \n",
    "    for word, real_count in cnt.items():\n",
    "        total_keys += 1\n",
    "        estimated_count = cms[word]\n",
    "        d = estimated_count - real_count\n",
    "        logd = mks1024.log_encode(estimated_count) - mks1024.log_encode(real_count) \n",
    "        total_estimated_freq += estimated_count\n",
    "        total_real_freq += real_count\n",
    "        ds = d*d\n",
    "        logds = logd * logd\n",
    "        if ds > mds:\n",
    "            md = d\n",
    "            mds = ds\n",
    "            mdw = word\n",
    "            mdc = estimated_count\n",
    "        variance += ds\n",
    "        logvariance += logds\n",
    "        \n",
    "    deviation = math.sqrt(variance / total_keys)\n",
    "    log_deviation = math.sqrt(logvariance / total_keys)\n",
    "    \n",
    "    ## Uncomment following lines for more detailed stats    \n",
    "    #print(\"Total keys: %d\" % total_keys)\n",
    "    #print(\"Total frequency reported %d (~ %f), expected %d (~ %f)\" \n",
    "    #      % (total_estimated_freq, total_estimated_freq / total_keys, total_real_freq, total_real_freq / total_keys))\n",
    "    #print(\"Deviation: %f\"% deviation)\n",
    "    #print(\"Max error: %d on key %s (expected %d, got %d)\"% (md, mdw, cnt[mdw], mdc))\n",
    "    return total_keys, deviation, log_deviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From https://stackoverflow.com/a/38515297\n",
    "import sys\n",
    "\n",
    "def get_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds size of objects\"\"\"\n",
    "    size = sys.getsizeof(obj)\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    obj_id = id(obj)\n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    # Important mark as seen *before* entering recursion to gracefully handle\n",
    "    # self-referential objects\n",
    "    seen.add(obj_id)\n",
    "    if isinstance(obj, dict):\n",
    "        size += sum([get_size(v, seen) for v in obj.values()])\n",
    "        size += sum([get_size(k, seen) for k in obj.keys()])\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum([get_size(i, seen) for i in obj])\n",
    "    return size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# tests a single run with Counter already loaded\n",
    "def test(cnt, size, algorithm = 'conservative'):\n",
    "    cms = bounter.CountMinSketch(size, algorithm=algorithm)\n",
    "\n",
    "    load(None, cms)\n",
    "    (total_keys, deviation, log_deviation) = stats(cnt, cms)\n",
    "\n",
    "    width = cms.width\n",
    "    depth = cms.depth\n",
    "    cms_size = 8*width*depth\n",
    "    cnt_size = get_size(cnt)\n",
    "    result = (width, depth, algorithm, deviation, log_deviation, cms.cardinality(), cms.sum)\n",
    "    ## Uncomment for more test statistics\n",
    "    #print(\"%d\\t%d\\t%s\\t%f\\t%f\\t%d\\t%d\" % result)\n",
    "    #print(\"Tested CMS with width %d (%f of words) and depth %d\" % (width, width / total_keys, depth))\n",
    "    #print(\"Deviation: %f\" % deviation)\n",
    "    #print(\"CMS size: %d bytes, compared to %d Counter size (%f)\" % (cms_size, cnt_size, cms_size / cnt_size))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section can be used to ad-hoc test count-min sketch implementation using values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of orig: 10700 entries in 905672 bytes from 64685 total words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width: 65536\ndepth: 4\nalgorithm: basic\ndeviation: 0.029002\nLog deviation: 0.029002\nCardinality: 10654\nTotal: 64685\nWall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_articles = 10\n",
    "max_words = 150000000\n",
    "cnt = Counter()\n",
    "words = load(cnt, None)\n",
    "print(\"Size of orig: %d entries in %d bytes from %d total words\" % (len(cnt), get_size(cnt), words))\n",
    "# modify parameters as you wish\n",
    "result = test(cnt, 1, 'basic')\n",
    "\n",
    "print(\"width: %d\\ndepth: %d\\nalgorithm: %s\\ndeviation: %f\\nLog deviation: %f\\nCardinality: %d\\nTotal: %d\" % result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of orig: 22559 entries in 2608750 bytes from 210713 total words\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "max_articles = 50\n",
    "max_words = 150000000\n",
    "\n",
    "cnt = Counter()\n",
    "words = load(cnt, None)\n",
    "results = []\n",
    "print(\"Size of orig: %d entries in %d bytes from %d total words\" % (len(cnt), get_size(cnt), words))\n",
    "for size in [1,2]: # all different sizes\n",
    "    for algorithm in ['basic', 'conservative', 'logcons1024']:\n",
    "            result = test(cnt, size, algorithm)\n",
    "            results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65536\t4\tbasic\t0.123845\t0.123845\t22741\t210713\n65536\t4\tconservative\t0.065573\t0.065573\t22741\t210713\n131072\t4\tlogcons1024\t2.974357\t0.450876\t22741\t210713\n131072\t4\tbasic\t0.035854\t0.035854\t22741\t210713\n131072\t4\tconservative\t0.018832\t0.018832\t22741\t210713\n262144\t4\tlogcons1024\t1.629538\t0.255443\t22741\t210713\n"
     ]
    }
   ],
   "source": [
    "for result in results:\n",
    "    print(\"%d\\t%d\\t%s\\t%f\\t%f\\t%d\\t%d\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be used to manually sanity-test a logcounter implementation.\n",
    "The result should be in the same order of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 997376 (0.997376 of original 1000000)\nCounter difference: -5 (expected 11169, actual 11164)\n"
     ]
    }
   ],
   "source": [
    "expected = 1000000\n",
    "mks = bounded_counter.CountMinSketch(width=1, depth=1, algorithm='logcons1024')\n",
    "for i in range(expected):\n",
    "    mks.increment(1)\n",
    "actual = mks[1]\n",
    "print(\"Got %d (%f of original %d)\" % (actual, actual / expected, expected))\n",
    "log_actual = mks.log_encode(actual)\n",
    "log_expected = mks.log_encode(expected)\n",
    "print(\"Counter difference: %d (expected %d, actual %d)\" % (log_actual - log_expected, log_expected, log_actual))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}